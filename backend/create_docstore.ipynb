{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huy/miniconda3/envs/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./vectorstore\n"
     ]
    }
   ],
   "source": [
    "from app.containers import Container\n",
    "container = Container()\n",
    "container.config.from_yaml(\"config.yaml\")\n",
    "retriever_handler = container.retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_handler = container.llm()\n",
    "await llm_handler.generate_response([{\"role\":\"user\", \"content\":\"Hello\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retriever_handler.add_documents(\"./ASEAN.docx\", \"asian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_agent = container.main_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\":\"user\", \"content\":\"How many times has Vietnam been the ASEAN chair?\"}]\n",
    "async for chunk in await main_agent.response(messages):\n",
    "    print(chunk, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_file_metadata_func(\"./ASEAN.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.containers import Container\n",
    "container = Container()\n",
    "container.config.from_yaml(\"config.yaml\")\n",
    "\n",
    "container.wire(modules=[__name__])\n",
    "chat_service = container.chat_service()\n",
    "from uuid import UUID, uuid4\n",
    "from app.schema import Message\n",
    "\n",
    "async for content in chat_service.stream_response(id=uuid4(), message=Message(id = str(uuid4()), role=\"user\", content=\"Xin chào?\")):\n",
    "    print(content, end='', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import UUID, uuid4\n",
    "from app.schema import Message\n",
    "\n",
    "async for content in chat_service.stream_response(id=uuid4(), message=Message(id = str(uuid4()), role=\"user\", content=\"Việt Nam gia nhập ASEAN vào năm nào?\")):\n",
    "    print(content, end='', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write code to load config from config.yaml\n",
    "from yaml import load, Loader\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = load(f, Loader=Loader)\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "client = AsyncOpenAI(api_key=config[\"llm\"][\"api_key\"])\n",
    "import pyaudio\n",
    "\n",
    "async def stream_audio():\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=8,\n",
    "                    channels=1,\n",
    "                    rate=24_000,\n",
    "                    output=True)\n",
    "\n",
    "    async with client.audio.speech.with_streaming_response.create(\n",
    "            model=\"tts-1\",\n",
    "            voice=\"alloy\",\n",
    "            input=\"\"\"InvokerAI có thể nói là sự kết hợp của Automatic1111 và ComfyUI kèm với đó là sự nâng cấp đang kể về giao diện hiện đại hơn. Hiện tại InvokerAI có thể hoạt động trên cả 2 loại generate ảnh là workflow note kéo thả và generate ảnh mặc định theo giao diện có sẵn. Invoker khá chú trọng tới trải nghiệm người dùng khi cho phép quản lý ảnh và thư viện tài nguyên một cách nhất quán ngay trên giao diện sử dụng. Tuy nhiên Invoker lại không cho phép phát triển các extension mở, các update công nghệ mới khá chậm dẫn đến việc khá kén người dùng phổ thông. Ngoài ra khi sử dụng Invoker AI, các cú pháp về prompt cũng được viết khác hoàn toàn cho với ComfyUI và Automatic cũng là một điểm trừ khiến cho người dùng khó tiếp cận.\"\"\",\n",
    "            response_format=\"pcm\"\n",
    "    ) as response:\n",
    "        async for chunk in response.iter_bytes(1024):\n",
    "            stream.write(chunk)\n",
    "            yield chunk\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "# To run the async generator in Jupyter notebook\n",
    "async for chunk in stream_audio():\n",
    "    pass  # or do something with each chunk if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from voice.stt import STT\n",
    "from fastapi import UploadFile\n",
    "stt = STT(api_key=config[\"llm\"][\"groq_api_key\"])\n",
    "import io\n",
    "# Open the file in binary mode ('rb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./sample-0.mp3\", \"rb\") as f:\n",
    "    file_content = f.read()\n",
    "    # Create UploadFile with the file content\n",
    "    upload_file = UploadFile(filename=\"sample-0.mp3\", file=io.BytesIO(file_content))\n",
    "    result = await stt.generate_audio(upload_file)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import io\n",
    "\n",
    "async def test_stt_endpoint():\n",
    "    # Replace with your actual audio file path\n",
    "    audio_file_path = \"./sample-0.mp3\"\n",
    "    \n",
    "    # Read the audio file\n",
    "    with open(audio_file_path, \"rb\") as f:\n",
    "        file_content = f.read()\n",
    "    \n",
    "    # Create the form data\n",
    "    data = aiohttp.FormData()\n",
    "    data.add_field('input',\n",
    "                   io.BytesIO(file_content),\n",
    "                   filename='audio.mp3',\n",
    "                   content_type='audio/mpeg')\n",
    "    \n",
    "    # Make the request\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post('http://localhost:8000/stt', data=data) as response:\n",
    "            # Print status\n",
    "            print(f\"Status: {response.status}\")\n",
    "            \n",
    "            # Get the response\n",
    "            result = await response.text()\n",
    "            print(f\"Response: {result}\")\n",
    "\n",
    "# Run the test\n",
    "await test_stt_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import uuid\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "async def test_chat_and_save_audio():\n",
    "    API_URL = \"http://localhost:8000/chat-to-audio\"\n",
    "    \n",
    "    request_data = {\n",
    "        \"conversation_id\": str(uuid.uuid4()),\n",
    "        \"message\": {\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Bạn có nói tục được không ?\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Tạo thư mục audio nếu chưa tồn tại\n",
    "    if not os.path.exists('audio'):\n",
    "        os.makedirs('audio')\n",
    "    \n",
    "    # Tạo tên file với timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"audio/response_{timestamp}.mp3\"\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(API_URL, json=request_data) as response:\n",
    "            print(f\"Status: {response.status}\")\n",
    "            \n",
    "            if response.status == 200:\n",
    "                # Mở file để ghi\n",
    "                with open(filename, 'wb') as f:\n",
    "                    while True:\n",
    "                        chunk = await response.content.read(1024)\n",
    "                        if not chunk:\n",
    "                            break\n",
    "                        f.write(chunk)\n",
    "                print(f\"Audio đã được lưu tại: {filename}\")\n",
    "            else:\n",
    "                error_text = await response.text()\n",
    "                print(f\"Error Response: {error_text}\")\n",
    "\n",
    "# For Jupyter notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Run the test\n",
    "await test_chat_and_save_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "async def test_audio_to_audio():\n",
    "    API_URL = \"http://145.223.21.25:8001/audio-to-audio\"\n",
    "    AUDIO_PATH = \"./audio/response_20241113_174510.mp3\"\n",
    "    \n",
    "    if not os.path.exists(AUDIO_PATH):\n",
    "        print(f\"File không tồn tại: {AUDIO_PATH}\")\n",
    "        return\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = \"./output_audio\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Generate output filename with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_filename = f\"{output_dir}/response_{timestamp}.mp3\"\n",
    "\n",
    "    # Tạo form data\n",
    "    form = aiohttp.FormData()\n",
    "    form.add_field('conversation_id', str(uuid.uuid4()))\n",
    "    form.add_field('audio_file', \n",
    "                  open(AUDIO_PATH, 'rb'),\n",
    "                  filename='audio.mp3',\n",
    "                  content_type='audio/mpeg')\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(API_URL, data=form) as response:\n",
    "            print(f\"Status: {response.status}\")\n",
    "            \n",
    "            if response.status == 200:\n",
    "                # Save the audio response to file\n",
    "                with open(output_filename, 'wb') as f:\n",
    "                    async for chunk in response.content.iter_chunked(1024):\n",
    "                        f.write(chunk)\n",
    "                \n",
    "                print(f\"Đã lưu audio response vào file: {output_filename}\")\n",
    "            else:\n",
    "                error_text = await response.text()\n",
    "                print(f\"Error Response: {error_text}\")\n",
    "\n",
    "# For Jupyter notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Run the test\n",
    "await test_audio_to_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Read your audio file\n",
    "with open('./audio/response.wav', 'rb') as audio_file:\n",
    "    audio_bytes = audio_file.read()\n",
    "    base64_audio = base64.b64encode(audio_bytes).decode('utf-8')\n",
    "    print(base64_audio)  # Copy this output to use in Postman"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
